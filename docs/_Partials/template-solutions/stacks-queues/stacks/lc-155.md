```python
class MinStack:
    def __init__(self):
        self.stack = []
        self.min_stack = []

    def push(self, val: int) -> None:
        self.stack.append(val)
        if not self.min_stack:
            self.min_stack.append(val)
        else:
            curr_min = self.min_stack[-1]
            self.min_stack.append(min(val, curr_min))

    def pop(self) -> None:
        self.stack.pop()
        self.min_stack.pop()

    def top(self) -> int:
        return self.stack[-1]

    def getMin(self) -> int:
        return self.min_stack[-1]
```

The requirement is to implement a solution with $O(1)$ time complexity for each function (i.e., `push`, `pop`, `top`, and `getMin`), and this is a hint in itself. All stacks would generally be designed to make it possible for us to get the minimum (or maximum) if there were no tradeoffs. Of course there must be a tradeoff here, notably one of space. So how should we use space to make each function $O(1)$, particularly the `getMin` function?

The answer is to maintain *two* stacks, the stack itself, `self.stack`, as well as a stack that only keeps track of the minimums so far, `self.min_stack`. This allows us to keep the stacks in lockstep and to perform normal stack operations as desired while at the same time making it easy to get minimums in $O(1)$ time.