import LC from '@site/src/components/LC';

The main idea in each approach below is effectively to "rotate" elements in some way so that the most recent element added is accessible from the front (since we can only pop elements in a queue from the first given its FIFO nature). Approach 1 is the intended solution on LeetCode (and probably what would be acceptable in an interview), but approaches 2 and 3 offer seam neat insights for clever optimizations.

<details>
<summary> Approach 1 (one queue, O(n) pushes with self-rotations)</summary>

```python
class MyStack:
    def __init__(self):
        self.queue = deque()

    def push(self, x: int) -> None:
        self.queue.append(x)
        size = len(self.queue)
        while size > 1:
            self.queue.append(self.queue.popleft())
            size -= 1
        
    def pop(self) -> int:
        return self.queue.popleft()

    def top(self) -> int:
        return self.queue[0]

    def empty(self) -> bool:
        return len(self.queue) == 0
```

The key to solving a similar problem, namely <LC id='232' type='long' ></LC>, was to take advantage of the fact that popping elements from a stack meant obtaining them *in reverse order* compared to how they are added to the stack. This meant we could use two stacks effectively to simulate a queue, where we kept adding elements to one stack (the "enqueued" stack) and we'd pop elements from the other stack (the "dequeue" stack) once a dequeue operation was requested &#8212; the main trick was that we only popped all the elements from the "enqueued" stack to "dequeue" stack when a dequeue operation was requested and the dequeue stack was empty. This meant we could perform the operation in amortized $O(1)$. That's not the case here.

Queues are FIFO so popping elements from the left in one queue and appending them to the right in another queue means elements would be added to the second queue in the same order they were added to the first queue. That is definitely not desirable. The main trick for this problem, which is easy to miss at first because it seems like there must be a more performant way to accomplish this (see Approach 2), is to use a single queue and *rotate* elements through the queue every time a new element is added so that the new element becomes the left-most element of the queue. Each "push" operation for the stack we're trying to implement requires appending an element to the queue and *then* rotating through all elements by popping from the left and appending the popped element to the right until the newly added element is the left-most element. For example, consider how the numbers `2, 7, 8, 4` would be added to the queue to simulate a stack:

```python
# first element (2) pushed
[2]

# second element (7) pushed 
[2]       # start state
[2,7]     # 7 gets pushed
[7,2]     # 2 gets popped from the left and pushed to the right

# third element (8) pushed
[7,2]     # start state
[7,2,8]   # 8 gets pushed
[2,8,7]   # 7 gets popped from the left and pushed to the right
[8,7,2]   # 2 gets popped from the left and pushed to the right

# fourth element (4) pushed
[8,7,2]   # start state
[8,7,2,4] # 4 gets pushed
[7,2,4,8] # 8 gets popped from the left and pushed to the right
[2,4,8,7] # 7 gets popped from the left and pushed to the right
[4,8,7,2] # 2 gets popped from the left and pushed to the right
```

Each push operation for the stack ultimately results in all elements being stored in the deque in *reverse order*, which is the desired effect. The push operation costs $O(n)$ and is really the only complicated operation, but it can be a head scratcher if you haven't seen it before.

</details>

<details>
<summary> Approach 2 (two queues, amortized O(sqrt(n)) pushes with self-rotations and cache) </summary>

```python
class MyStack:
    def __init__(self):
        self.cache = deque()
        self.storage = deque()

    def push(self, x: int) -> None:
        self.cache.append(x)
        size = len(self.cache)
        while size > 1:
            self.cache.append(self.cache.popleft())
            size -= 1
            
        if len(self.cache) * len(self.cache) > len(self.storage):
            while self.storage:
                self.cache.append(self.storage.popleft())
                
            self.cache, self.storage = self.storage, self.cache

    def pop(self) -> int:
        if self.cache:
            return self.cache.popleft()
        else:
            return self.storage.popleft()
        
    def top(self) -> int:
        if self.cache:
            return self.cache[0]
        else:
            return self.storage[0]
        
    def empty(self) -> bool:
        return len(self.cache) == 0 and len(self.storage) == 0
```

The approach above is based on [this solution](https://cstheory.stackexchange.com/a/2589/56056). The core idea of maintaining stack order by rotating through elements is still present from Approach 1. But it seemed like there must be a more performant way to push elements to our stack than requiring an $O(n)$ approach every time (i.e., rotating through all elements for each push).

The core of the solution above is the same as that in Approach 1 (i.e., rotating through elements), but now we're effectively trying to reduce the amount of rotating we have to do for each push. The idea is to maintain two queues, one that acts as a `cache` and one that acts as main `storage`. How does this help? Costly rotations arising from push operations will only be executed on the `cache`, and our goal will be to keep the *size* of `cache` small. When the size of `cache` exceeds the square root of the size of `storage`, the following will happen:

- All of the elements in `storage` will be popped and appended to `cache`.
- The variable designations will be swapped so now `cache` is empty and `storage` has all elements in the stack.

Important to note is that both `cache` and `storage` will always be maintained in LIFO order, with `cache` holding the newest elements at the top of the stack and `storage` holding the oldest. An example that illustrates the mechanics of how this works will be most helpful. Suppose we're trying to push the following elements to our stack: `1`, `2`, `3`, `4`, `5`, `6`, `7`, `8`. This is how the process would look:

```python
##### PUSHING (1)
cache = []    # start state
storage = []  # start state

cache = [1]   # after adding 1
storage = []

# len(cache) * len(cache) = 1 * 1 = 1 > 0 = len(storage)  [YES, transfer and reassign]
# self.storage is empty so the empty pop doesn't happen: self.cache.append(self.storage.popleft())
# we still end up swapping/reassigning cache and storage
cache = []
storage = [1]


##### PUSHING (2)
cache = []      # start state
storage = [1]

cache = [2]    # after pushing 2
storage = [1]

# len(cache) * len(cache) = 1 * 1 = 1 > 1 = len(storage) [NO, terminate push op]


##### PUSHING (3)
cache = [2]      # start state
storage = [1]

cache = [2,3]    # after pushing 3
cache = [3,2]    # after rotating
storage = [1]

# len(cache) * len(cache) = 2 * 2 = 4 > 1 = len(storage) [YES, transfer and reassign]
cache = [3,2,1] # pop left all elements in storage and append to cache
storage = []    # pop ALL elements from storage from the left and append to cache until empty

cache = []        # swap and reassign
storage = [3,2,1]


##### PUSHING (4)
cache = []        # start state
storage = [3,2,1]

cache = [4]       # after pushing 4
storage = [3,2,1]

# len(cache) * len(cache) = 1 * 1 = 1 > 3 = len(storage) [NO, terminate push op]


##### PUSHING (5)
cache = [4]         # start state
storage = [3,2,1]

cache = [4,5]       # after pushing 5
cache = [5,4]       # after rotating
storage = [3,2,1]

# len(cache) * len(cache) = 2 * 2 = 4 > 3 = len(storage) [YES, transfer and reassign]
cache = [5,4,3,2,1] # pop left all elements in storage and append to cache
storage = []        # pop ALL elements from storage from the left and append to cache until empty

cache = []            # swap and reassign
storage = [5,4,3,2,1]


##### PUSHING (6)
cache = []            # start state
storage = [5,4,3,2,1]

cache = [6]           # after pushing 6
storage = [5,4,3,2,1]

# len(cache) * len(cache) = 1 * 1 = 1 > 5 = len(storage) [NO, terminate push op]


##### PUSHING (7)
cache = []              # start state
storage = [5,4,3,2,1]

cache = [6,7]           # after pushing 7
cache = [7,6]           # after rotating
storage = [5,4,3,2,1]

# len(cache) * len(cache) = 2 * 2 = 4 > 5 = len(storage) [NO, terminate push op]


##### PUSHING (8)
cache = [7,6]               # start state
storage = [5,4,3,2,1]

cache = [7,6,8]             # after pushing 8
cache = [8,7,6]             # after rotating
storage = [5,4,3,2,1]

# len(cache) * len(cache) = 3 * 3 = 6 > 5 = len(storage) [YES, transfer and reassign]
cache = [8,7,6,5,4,3,2,1]   # pop left all elements in storage and append to cache
storage = []                # pop ALL elements from storage from the left and append to cache until empty

cache = []                  # swap and reassign
storage = [8,7,6,5,4,3,2,1]
```

The mechanics of the process illustrated above show how `cache` always maintains the top elements of the stack until its size limit (the square root of the size of `storage`) has been exceeded. Then all elements from `storage` are transfered to `cache` so as to maintain the LIFO order of the stack. Then `cache` and `storage` are swapped/reassigned so that `cache` is now empty again. Hence, `storage` is the main storage for the stack and keeps growing indefinitely while `cache`, on the other hand, is sort of an intermediary device that's used to make sure `storage` grows in size as efficient as possible.

As [this post notes](https://cstheory.stackexchange.com/a/2589/56056):

> `push` works in $O(\sqrt{n})$ amortized time. There are two cases: if $|\texttt{cache}| < \sqrt{|\texttt{storage}|}$, then `push` takes $O(\sqrt{n})$ time. If $|\texttt{cache}| \geq \sqrt{|\texttt{storage}|}$, then `push` takes $O(n)$ time, but after this operation `cache` will be empty. It will take $O(\sqrt{n})$ time before we get to this case again, so the amortized time is $O(n/\sqrt{n})=O(\sqrt{n})$ time.

</details>

<details>
<summary> Approach 3 (dynamic number of deques, O(1) operations)</summary>

```python
class MyStack:
    def __init__(self):
        self.queue = deque()

    def push(self, x: int) -> None:
        new_queue = deque()
        new_queue.append(x)
        new_queue.append(self.queue)
        self.queue = new_queue
        
    def pop(self) -> int:
        pop_val = self.queue.popleft()
        self.queue = self.queue.popleft()
        return pop_val

    def top(self) -> int:
        return self.queue[0]

    def empty(self) -> bool:
        return len(self.queue) == 0
```

The solution above, inspired by [Stefan Pochmann's](https://leetcode.com/problems/implement-stack-using-queues/discuss/62522/O(1)-purely-with-queues/64180), shows it is *possible* to implement `MyStack` using only $O(1)$ operations if we get really creative (even though this may be thought of as "cheating" in some sense because we use an unlimited number of deques). This solution takes advantage of the fact that Python is fundamentally a *reference-based* language: adding a queue object into another *does not* copy the entire contents &#8212; this is an $O(1)$ operation since a linked list is used under the hood (for Python deques).

To illustrate exactly how and why the solution above works, considering pushing the following elements to our stack: `1`, `2`, `3`. Below, we'll let `D` represent a deque collection:

```python
# starting state
self.queue = D()


# pushing 1
new_queue = D(1) # after pushing 1
          = D(1, D()) # after pushing self.queue

self.queue = D(1, D()) # end state after pushing x


# pushing 2
new_queue = D(2) # after pushing 2
          = D(2, D(1, D())) # after pushing self.queue

self.queue = D(2, D(1, D())) # end state after pushing 2


# pushing 3
new_queue = D(3) # after pushing 3
          = D(3, D(2, D(1, D()))) # after pushing self.queue

self.queue = D(3, D(2, D(1, D()))) # end state after pushing 3
```

The process illustrated above shows how we always have access to the most recently added element (desirable for stacks because of the LIFO processing). Popping an element is also easy. Consider the final state of the example above: popping an element from the left (a queue operation) of `self.queue` means popping the left-most element of `D(3, D(2, D(1, D())))`, which is the integer `3`, as desired. After this pop, we have `self.queue = D(D(2, D(1, D())))`, which is not desirable because now if we pop left then we'll get a deque and not an integer, as desired and required. But this is not much of an issue because all we have to do is reassign `self.queue` to be the left-most popped element (after popping the `3`, the deque only consists of one element, the deque with everything else in the stack): `self.queue = D(2, D(1, D()))`. Now we can pop left to get the `2` and reassign by popping left again to get `D(1, D())`. Finally, we can pop left to get the `1` and reassign by popping left again to end up back where we started: `D()`.

</details>
