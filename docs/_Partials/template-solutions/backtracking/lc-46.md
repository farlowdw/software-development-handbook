```python
class Solution:
    def permute(self, nums: List[int]) -> List[List[int]]:
        def backtrack(curr):
            if len(curr) == len(nums):
                permutations.append(curr[:]) # note that we append a _copy_ of curr
                return
            
            for num in nums:
                if num not in curr:
                    curr.append(num)
                    backtrack(curr)
                    curr.pop()
            
        permutations = []
        backtrack([])
        
        return permutations
```

What actually *is* a permutation of `nums`? It's essentially *all* possible orderings of the elements of `nums` such that no element is duplicated. A backtracking strategy to generate all permutations sounds promising &#8212; what would the base case be? It would be when the current permutation being generated, say `curr`, has the same length as the input array `nums`: `curr.length == nums.length` (of course, this assumes we've done our due diligence and have prevented duplicates from being added to `curr`). The base case of `curr.length == nums.length` means we have completed the process of generating a permutation and we cannot go any further; specifically, if we look at the process of generating permutations as a tree, then completing the generation of a permutation means we have reached a leaf node, as illustrated in the following image for the input `nums = [1, 2, 3]`:

<div align='center' className='centeredImageDiv'>
  <img width='700px' src={require('@site/static/img/templates/backtracking/f1.png').default} />
</div>

Building *all* permutations for this problem, where the input is an array of numbers, means we need all elements to make an appearance at the first index, all other elements to make an appearance at the second index, and so on. Hence, we should loop over all elements of `nums` for each call to our `backtrack` function, where we should always check to see if a number is already in `curr` before adding it to `curr`. Each call to `backtrack` is like visiting a node in the tree of candidates being generated. The leaves are the base cases/answers to the problem.

For the solution given above, if we simply add `print(curr)` after the line `curr.append(num)`, then we can very clearly see how each call to `backtrack` is like visiting a node in the tree (it's like performing a DFS on an imaginary tree):

```python
[1]
[1, 2]
[1, 2, 3]   # complete permutation (leaf node)
[1, 3]
[1, 3, 2]   # complete permutation (leaf node)
[2]
[2, 1]
[2, 1, 3]   # complete permutation (leaf node)
[2, 3]
[2, 3, 1]   # complete permutation (leaf node)
[3]
[3, 1]
[3, 1, 2]   # complete permutation (leaf node)
[3, 2]
[3, 2, 1]   # complete permutation (leaf node)
```

The entire list of complete permutations is then returned as the answer:

```python
[[1, 2, 3], [1, 3, 2], [2, 1, 3], [2, 3, 1], [3, 1, 2], [3, 2, 1]]
```

The time complexity above effectively amounts to *roughly* $O(n^2\cdot n!)$, because we iterate through all of `nums` for each call to `backtrack`, and membership to `curr` is a linear cost when `curr` is an array, and then we're guaranteed to make $n$ calls to `backtrack`, and each call to `backtrack` then results in $n - 1$ calls, and so forth. If we wanted to make a micro-optimization, then we could introduce a hash set to make the membership checks on `curr` $O(1)$ instead of $O(n)$, but this change pales in comparison to the factorial cost of calling `backtrack` so many times:

```python
class Solution:
    def permute(self, nums: List[int]) -> List[List[int]]:
        def backtrack(curr):
            if len(curr) == len(nums):
                permutations.append(curr[:])
                return
            
            for num in nums:
                if num not in lookup:
                    curr.append(num)
                    lookup.add(num)
                    backtrack(curr)
                    curr.pop()
                    lookup.remove(num)
        
        lookup = set()
        permutations = []
        backtrack([])
        
        return permutations
```
