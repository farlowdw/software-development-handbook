You are given a **0-indexed** array `points` representing integer coordinates of some points on a 2D plane, where <code>points[i] = [x<sub>i</sub>, y<sub>i</sub>]</code>.

The distance between two points is defined as their Manhattan distance.

Return the **minimum** possible value for **maximum** distance between any two points by removing exactly one point.