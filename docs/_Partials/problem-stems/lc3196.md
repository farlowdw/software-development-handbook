You are given an integer array `nums` with length `n`.

The **cost** of a subarray `nums[l..r]`, where `0 <= l <= r < n`, is defined as:

<code>cost(l, r) = nums[l] - nums[l + 1] + ... + nums[r] * (−1)<sup>r - l</sup></code>

Your task is to **split** `nums` into subarrays such that the **total cost** of the subarrays is **maximized**, ensuring each element belongs to **exactly one** subarray.
<sub></sub>

Formally, if `nums` is split into `k` subarrays, where `k > 1`, at indices <code>i<sub>1</sub>, i<sub>2</sub>, ..., i<sub>k - 1</sub></code>, where <code>0 &lt;= i<sub>1</sub> &lt; i<sub>2</sub> &lt; ... &lt; i<sub>k - 1</sub> &lt; n - 1</code>, then the total cost will be:

<code>cost(0, i<sub>1</sub>) + cost(i<sub>1</sub> + 1, i<sub>2</sub>) + ... + cost(i<sub>k - 1</sub> + 1, n − 1)</code>

Return an integer denoting the maximum total cost of the subarrays after splitting the array optimally.

**Note:** If `nums` is not split into subarrays, i.e. `k = 1`, the total cost is simply `cost(0, n - 1)`.